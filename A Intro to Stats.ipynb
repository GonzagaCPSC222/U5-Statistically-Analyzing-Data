{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Intro to Stats\n",
    "What are our learning objectives for this lesson?\n",
    "* Learn terms related to statistics\n",
    "* Summarize data with simple statistics\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistics\n",
    "When we learned about tabular data, we talked about how instances in a dataset are sampled from the \"universe of instances.\" The key here is we have a few observations (e.g. the instances), but not all observations (e.g. the universe). In the stats world, we would say our dataset is a \"sample\" of the \"population\", where the population is the universe of instances. \n",
    "\n",
    "### Example\n",
    "Let's take a look at an example. Suppose we want to find out how many emails a college student receives per day in September of this year. If we asked students in this class how many emails they received during September of this year, we would have a \"sample\". This sample is not representative of the entire population of college students. There are other classes at Gonzaga we did not sample and there are other universities besides Gonzaga. The population would consist of the number of emails **all** college students in the world received during September. It is typically very time consuming and expensive to collect data for an entire population, so we usually collect a sample, then try to draw statistical inferences about the population using the sample. Welcome to wonderful world of stats!! :) \n",
    "\n",
    "### Key Stats Terms\n",
    "* Parameter: any measurable characteristic of a population (e.g. population mean)\n",
    "* Statistic: any measurable characteristic of a sample (e.g. sample mean)\n",
    "        \n",
    "## Summary Statistics\n",
    "Summary statistics give (initial) insights into a dataset by summarizing the data into a single point. Examples of summary statistics include:\n",
    "1. Number of instances (how many rows)\n",
    "2. Min and max attribute values\n",
    "    * Q: Do these make sense for both categorical and continuous attributes?\n",
    "        * Ordinal, but not Nominal\n",
    "        * Much easier if numeric!\n",
    "        * Can only count number of each nominal value\n",
    "    * Q: What should be done with null (NA) values?\n",
    "        * Really, undefined / unknown\n",
    "        * In practice just ignore them\n",
    "3. Middle values of a distribution (aka \"Central Tendency\")\n",
    "    * Mid value: `(max + min) / 2.0` \n",
    "        * AKA \"Midrange\"\n",
    "    * (Arithmetic) Mean $\\bar{x} = (x_1 + x_2 + ... + x_n) / n$\n",
    "        * AKA average\n",
    "        * Python: `sum(column) / float(len(column))`\n",
    "        * Q: Problems with the mean? ... sensitive to extremes (e.g., outliers)\n",
    "        * Q: Make sense for categorical and continuous?\n",
    "            * only Interval or Ratio (same widths)\n",
    "    * Median\n",
    "        * The middle value in a set of sorted values\n",
    "        * If even number of values, halfway between the two middles\n",
    "        * Better measure for skewed data\n",
    "        * Can be expensive for large data sets (sorting!)\n",
    "    * Mode\n",
    "        * Value(s) that occurs most frequently\n",
    "    * Typically assume data is unimodal (one mode), e.g., normally distributed\n",
    "    * Q: How might we compute the mode in Python?\n",
    "4. Data Dispersion (Spread)\n",
    "    * Range (max - min)\n",
    "    * Quantiles: (Roughly) equal size partitions of data (if sorted from smallest to largest)\n",
    "        * \"2-quantiles\" is the data point that divides into two halves (AKA median)\n",
    "        * \"Quartiles\" is three data points that divide into four groups\n",
    "            * Used as part of box plots (more later)\n",
    "        * Interquartile range (IQR) is distance between 1st and 3rd quartiles\n",
    "        * \"Percentiles\" are 100-quantiles (100 groups)\n",
    "    * Variance and Standard Deviation\n",
    "        * Variance measures how spread out the data is (small implies data close to mean, large implies data spread out) $$\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n}$$\n",
    "        * Standard Deviation is square root of variance\n",
    "            * Python: `numpy.std(vals)` \n",
    "                * ... more on numpy later\n",
    "        * For a normal (i.e., Gaussian) data distribution\n",
    "            * About 68% of values are within 1 standard deviation of mean\n",
    "            * About 95% of values are within 2 standard deviations\n",
    "            * About 99.7% of values are within 3 standard deviations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
